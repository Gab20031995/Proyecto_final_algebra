# -*- coding: utf-8 -*-
"""Proyecto_final_Algebra.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C4MptMPENu1-j4D1H814SBSROVwITZ5o

# Carga de datos y J.SON con API de KAGGLE
"""

from google.colab import files

# Sube tu archivo kaggle.json
files.upload()

# Mueve el archivo kaggle.json a la ubicación correcta
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!pip install kaggle

# Descarga el conjunto de datos usando la API de Kaggle
!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia

"""# Desconprime el .zip de los datos


"""

!unzip chest-xray-pneumonia.zip -d datos_pneumonia

"""# 2

"""

!ls datos_pneumonia

!ls datos_pneumonia/chest_xray

import os

# Ruta al directorio donde se extrajeron los datos
data_dir = "datos_pneumonia"

# Función para mostrar la estructura de carpetas
def mostrar_estructura_carpetas(data_dir):
    for root, dirs, files in os.walk(data_dir):
        if dirs:
            print(f"Directorio: {root}")
            print(f"Subdirectorios: {dirs}")
            print("--------------------")

# Mostrar la estructura de carpetas
mostrar_estructura_carpetas(data_dir)

from tqdm import tqdm
import cv2
import os
import numpy as np

def cargar_datos(data_dir, classes):
    data = []
    errores = 0

    for clase in classes:
        path = os.path.join(data_dir, clase)
        class_num = classes.index(clase)

        for img in tqdm(os.listdir(path), desc=f'Cargando {clase}'):
            try:
                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)
                img_resized = cv2.resize(img_array, (128, 128))
                # Normalizar los valores de píxeles entre 0 y 1
                img_resized = img_resized / 255.0
                data.append([img_resized, class_num])
            except Exception as e:
                errores += 1
                print(f"Error al procesar {clase}/{img}: {str(e)}")

    print(f"Total de errores: {errores}")
    return np.array(data)

# Ejemplo de uso
data_dir = 'datos_pneumonia/chest_xray/train'  # Ajusta la ruta según tu estructura
classes = ['NORMAL', 'PNEUMONIA']

data_val = 'datos_pneumonia/chest_xray/val'


# Cargar datos
datos = cargar_datos(data_dir, classes)
datos_val = cargar_datos(data_val, classes)

mostrar_estructura_carpetas(data_dir)

"""# Importación de los datos y aumento


"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Directorio principal
base_dir = '/content/datos_pneumonia/chest_xray'

# Directorio de entrenamiento
train_dir = os.path.join(base_dir, 'train')

# Subdirectorios
subdirs = ['PNEUMONIA', 'NORMAL']

# Función para cargar y preprocesar imágenes
def load_and_preprocess_images(base_dir, subdir, label, num_images=5, target_size=(224, 224)):
    directory = os.path.join(base_dir, subdir)
    fig, axes = plt.subplots(1, num_images, figsize=(15, 3))

    for i, filename in enumerate(os.listdir(directory)[:num_images]):
        img_path = os.path.join(directory, filename)
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # Redimensionar la imagen
        img = cv2.resize(img, target_size)

        # Normalizar la imagen
        img = img / 255.0

        axes[i].imshow(img)
        axes[i].set_title(label)
        axes[i].axis('off')

    plt.show()

# Aumento de datos utilizando ImageDataGenerator de TensorFlow
def data_augmentation(base_dir, subdir, label, num_images=5, target_size=(224, 224)):
    directory = os.path.join(base_dir, subdir)

    # Configuración del generador de imágenes
    datagen = ImageDataGenerator(
        rotation_range=40,#cambio
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest'
    )

    fig, axes = plt.subplots(1, num_images, figsize=(15, 3))

    for i, filename in enumerate(os.listdir(directory)[:num_images]):
        img_path = os.path.join(directory, filename)
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # Redimensionar la imagen
        img = cv2.resize(img, target_size)

        # Normalizar la imagen
        img = img / 255.0

        # Aumento de datos
        img = np.expand_dims(img, axis=0)
        augmented_img = datagen.flow(img).next()[0]

        axes[i].imshow(augmented_img)
        axes[i].set_title(label)
        axes[i].axis('off')

    plt.show()

# Cargar y preprocesar imágenes de PNEUMONIA
load_and_preprocess_images(train_dir, subdirs[0], 'Pneumonia')

# Cargar y preprocesar imágenes de NORMAL
load_and_preprocess_images(train_dir, subdirs[1], 'Normal')
print("-------------------------------------------------------------------------")
print("Aumento de la data")
# Aumento de datos para PNEUMONIA
data_augmentation(train_dir, subdirs[0], 'Pneumonia')

# Aumento de datos para NORMAL
data_augmentation(train_dir, subdirs[1], 'Normal')

"""# CNN (Entrenamiento)"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Directorio principal
base_dir = '/content/datos_pneumonia/chest_xray'

# Directorio de entrenamiento
train_dir = os.path.join(base_dir, 'train')

# Subdirectorios
subdirs = ['PNEUMONIA', 'NORMAL']

# Configuración del modelo CNN
model = Sequential()

model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))
model.add(MaxPooling2D(2, 2))

model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(2, 2))

model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D(2, 2))

model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D(2, 2))

model.add(Flatten())

model.add(Dense(512, activation='relu'))
model.add(Dropout(0.5))

model.add(Dense(1, activation='sigmoid'))  # Binary classification

# Compilar el modelo
model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

# Crear generadores de datos para entrenamiento y validación
train_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

# Entrenar el modelo
history = model.fit(train_generator, epochs=10, verbose=1)

# Visualizar resultados del entrenamiento
plt.plot(history.history['accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.show()

"""# PCA 1"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import backend as K
from sklearn.decomposition import PCA

# Obtener las representaciones intermedias de la primera capa convolucional
get_intermediate_output = K.function([model.layers[0].input], [model.layers[0].output])
batch = train_generator.next()
input_data = batch[0]
label_data = batch[1]

conv1_output = get_intermediate_output([input_data])[0]

# Aplanar los datos para que sean compatibles con PCA
conv1_output_flat = conv1_output.reshape(conv1_output.shape[0], -1)

# Aplicar PCA
pca = PCA(n_components=2)
pca_result = pca.fit_transform(conv1_output_flat)

# Visualizar los resultados de PCA
plt.scatter(pca_result[:, 0], pca_result[:, 1], c=label_data, cmap='viridis')
plt.title('PCA')
plt.xlabel('X')
plt.ylabel('Y')
plt.show()

"""# CNN (Evaluando)"""

# Compilar el modelo
model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

# Realizar predicciones en el conjunto de datos de validación
predicciones = model.predict(datos_val)

# Puedes utilizar las predicciones como lo necesites
# Por ejemplo, imprimir las primeras 5 predicciones
print(predicciones[:5])

# Visualizar resultados de las predicciones
# (esto depende de la naturaleza de tus datos y tu problema)
# Por ejemplo, podrías mostrar gráficos, tablas, etc.

# Compilar el modelo
model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

# Ejecutar el modelo
history = model.predict(datos_val, epochs=10, verbose=1)

# Visualizar resultados del entrenamiento
plt.plot(history.history['accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.show()

# Evaluar el modelo en el conjunto de prueba
test_loss, test_acc = model.evaluate(test_images, test_labels)
print(f'\nPrecisión en el conjunto de prueba: {test_acc}')

# Hacer predicciones en algunas imágenes del conjunto de prueba
predictions = model.predict(test_images[:5])

# Visualizar las imágenes y las predicciones
for i in range(5):
    plt.subplot(1, 5, i + 1)
    plt.imshow(test_images[i].reshape(28, 28), cmap='gray')
    plt.title(f'Predicción: {tf.argmax(predictions[i])}\nReal: {test_labels[i]}')
    plt.axis('off')

plt.show()